# -*- coding: utf-8 -*-
"""CNN Visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UumSkeVuCwgusRRJVz66uC8Z98gG1w2_
"""


import numpy as np

import torch
from torch.autograd import Variable
from torch.optim import SGD
import torch.nn as nn
from torchvision import models, transforms

from PIL import Image, ImageFilter, ImageChops

import os
import copy
import matplotlib
import matplotlib.pyplot as plt

from matplotlib import animation

import scipy.ndimage as ndimage

# %matplotlib inline

def recreate_image(im_as_var):
    reverse_mean = [-0.485, -0.456, -0.406]
    reverse_std = [1/0.229, 1/0.224, 1/0.225]
    recreated_im = copy.copy(im_as_var.data.numpy()[0])
    for c in range(3):
        recreated_im[c] /= reverse_std[c]
        recreated_im[c] -= reverse_mean[c]
    recreated_im[recreated_im > 1] = 1
    recreated_im[recreated_im < 0] = 0
    recreated_im = np.round(recreated_im * 255)

    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)
    # Convert RBG to GBR
    recreated_im = recreated_im[..., ::-1]
    recreated_im = ndimage.gaussian_filter(recreated_im, sigma=(1, 1, 0), order=0)
    return recreated_im

def preprocess_image(cv2im, resize_im=True):
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

    if resize_im:
        cv2im = Image.fromarray(cv2im).resize((224, 224))
    
    im_as_arr = np.float32(cv2im)
    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])
    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H
   
    for channel, _ in enumerate(im_as_arr):
        im_as_arr[channel] /= 255
        im_as_arr[channel] -= mean[channel]
        im_as_arr[channel] /= std[channel]
   
    im_as_ten = torch.from_numpy(im_as_arr).float()
    im_as_ten.unsqueeze_(0)
    im_as_var = Variable(im_as_ten, requires_grad=True)
    
    return im_as_var


loader = transforms.Compose([
    transforms.Resize((224, 224)), 
    transforms.ToTensor()
])

normalise = transforms.Normalize(
    mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225]
)

preprocess = transforms.Compose([
    loader,
    normalise
])

  

model = models.vgg16(pretrained=True)

print(model)

layers_num = len(list(model.features) + list(model.classifier))
print("tot layers: ", layers_num)

for param in model.parameters():
  param.requires_grad = False


"""## Deep Dream"""

import scipy.ndimage as nd
  
def objective_L2(dst, guide_features):
    return dst.data

def make_step(img, model, objective=objective_L2, control=None, step_size=1.5, end=28, jitter=32, clip=True):
    mean = np.array([0.485, 0.456, 0.406]).reshape([3, 1, 1])
    std = np.array([0.229, 0.224, 0.225]).reshape([3, 1, 1])
    
    src = Variable(torch.from_numpy(img).unsqueeze(0).cuda(), requires_grad=True)
   
    
    ox, oy = np.random.randint(-jitter, jitter+1, 2)
    src.data = torch.from_numpy(np.roll(np.roll(src.data.cpu().numpy(), ox, -1), oy, -2))
    
    dst = src
    for index, layer in enumerate(model.features):
      dst = layer(dst)
      if index == end:
        break
    
    dst.backward(objective(dst, control))
    ratio = np.abs(src.grad.data.cpu().numpy()).mean()
    src.data[0] = src.data[0] + step_size / ratio * src.grad.data 
    src  = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2)
    if clip:
      src[0, :, :, :] = np.clip(src[0, :, :, :], -mean / std, (1 - mean) / std)
    
    return src

  
def preproc(img):
  return np.float32(np.rollaxis(img, 2)[::-1]) - np.float32([0.485, 0.456, 0.406]).reshape([3, 1, 1])

def deproc(img):
  return np.dstack((img + np.float32([]).reshape([3, 1, 1]))[::-1])
                                                             
def deepdream(model, base_img, iter_n=10, octave_n=4, octave_scale=1.4, end=28, control=None, clip=True, objective=objective_L2, **step_params):
    octaves = [base_img]
    
    for i in range(octave_n - 1):
        octaves.append(nd.zoom(octaves[-1], (1, 1.0 / octave_scale, 1.0 / octave_scale), order=1))

    detail = np.zeros_like(octaves[-1])
    for octave, octave_base in enumerate(octaves[::-1]):
        h, w = octave_base.shape[-2:]
        
        if octave > 0:
            h1, w1 = detail.shape[-2:]
            detail = nd.zoom(detail, (1, 1.0 * h / h1, 1.0 * w / w1), order=1)
        
        src = octave_base + detail
        print(src.shape)
        #src.reshape(1, 3, h, w)
        #src.data[0] = octave_base + detail
        
        for i in range(iter_n):
            src = make_step(src, model, end=end, clip=clip, objective=objective, control=control, **step_params)
            print(octave, i, end)
        
        detail = src.data[0] - octave_base

    return deproc(src.data[0])

img = Image.open('sky.jpg')
print(img.size)
img = np.float32(img)
plt.imshow(Image.fromarray(np.uint8(img)))

plt.imshow(deepdream(model, img))