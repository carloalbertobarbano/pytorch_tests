{
  "cells": [
    {
      "metadata": {
        "_uuid": "2c2c966557b24c189b2e0688ea2c27bacae5be5b",
        "_cell_guid": "c3b96391-2148-43c8-9eb1-6f53c9c8a704"
      },
      "cell_type": "markdown",
      "source": "See kernel results at https://github.com/carloalbertobarbano/pytorch_tests/blob/master/VGG-16/VGG16_FeatureExtraction_OCT2017_Retina.ipynb"
    },
    {
      "metadata": {
        "id": "69iuBpidwheJ",
        "colab_type": "text",
        "_uuid": "c060d3a7eae2502855e84ae5eabd1a8c72fc4ea2",
        "_cell_guid": "07763a82-f724-46ec-a323-e1f26101dcf3"
      },
      "cell_type": "markdown",
      "source": "## Dataset loader"
    },
    {
      "metadata": {
        "_uuid": "052000903c6a7b947bbf6c0c443c060a05d88560",
        "_cell_guid": "d738efa9-2509-4b41-94eb-7c7796271bfa",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "!ls -l \"../input/kermany2018/oct2017/OCT2017 /test/DME\" | wc -l ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a735fdff0afe91f07dbb45bfbfd99565b27ba72",
        "_cell_guid": "e7d68254-09bc-4888-9a18-357d6756c636",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "!ls -l ../input/vgg16-transfer-learning-pytorch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xvsy0IR4wheJ",
        "_uuid": "83371f19c7f1e261bb0f9cc71f7a265c37a4c16a",
        "outputId": "bb02efaa-518c-4342-d6e5-7275a7d7fdd5",
        "colab_type": "code",
        "colab": {
          "height": 68,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525007461873,
          "elapsed": 1074,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "_cell_guid": "e9d7ef88-fdbd-4b73-b64f-70294976d238",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()  \n\ndata_dir = '../input/kermany2018/oct2017/OCT2017 '\nTRAIN = 'train'\nVAL = 'val'\nTEST = 'test'\n\ndata_transforms = {\n    TRAIN: transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    VAL: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    TEST: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\n\nimage_datasets = {x: datasets.ImageFolder(\n                        os.path.join(data_dir, x), \n                        transform=data_transforms[x]\n                     )\n                     for x in [TRAIN, VAL, TEST]}\n\ndataloaders = {x: torch.utils.data.DataLoader(\n                    image_datasets[x], batch_size=8,\n                    shuffle=True, num_workers=4\n                  )\n                  for x in [TRAIN, VAL, TEST]}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\nclass_names = image_datasets[TRAIN].classes\n\nprint(\"Classes: \")\nprint(image_datasets[TRAIN].classes)\n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6f1fb14iwheO",
        "colab_type": "text",
        "_uuid": "80417b6d4f2000be40245a090424b2452e1b78e1",
        "_cell_guid": "2ad1e66d-dcfc-429a-9664-e61b4d2944cc"
      },
      "cell_type": "markdown",
      "source": "## Utils"
    },
    {
      "metadata": {
        "id": "rphPgOQewheQ",
        "_uuid": "48e7f7c02cab559638af532e98d371ebd8c89bfa",
        "outputId": "0bec4c14-9968-4119-bb75-f896ddc21ebd",
        "colab_type": "code",
        "colab": {
          "height": 119,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525007467056,
          "elapsed": 1443,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "_cell_guid": "fd84399d-83f9-4af7-8767-fe1d32856493",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\ndef show_databatch(inputs, classes):\n    out = torchvision.utils.make_grid(inputs)\n    imshow(out, title=[class_names[x] for x in classes])\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders[TRAIN]))\nshow_databatch(inputs, classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WXgC3SYkwheT",
        "_uuid": "d7785c091b61ab0ddff8556c06bafc5f16037aa4",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "5e6e0c3f-19bd-4034-b408-eeffb9746275",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def visualize_model(vgg, num_images=6):\n    was_training = vgg.training\n    vgg.train(False)\n    vgg.eval() # Set model for evaluation\n    images_so_far = 0\n    fig = plt.figure()\n\n    for i, data in enumerate(dataloaders[TEST]):\n        print(\"BATCH {0}\".format(i))\n        inputs, labels = data\n        size = inputs.size()[0]\n        \n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n        \n        outputs = vgg(inputs)\n        \n        _, preds = torch.max(outputs.data, 1)\n        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n        \n        print(\"Ground truth:\")\n        show_databatch(inputs.data.cpu(), labels.data.cpu())\n        print(\"Prediction:\")\n        show_databatch(inputs.data.cpu(), predicted_labels)\n        \n        del inputs, labels, outputs, preds, predicted_labels\n        torch.cuda.empty_cache()\n        \n        images_so_far += size\n        if images_so_far >= num_images:\n            break\n        \n    vgg.train(mode=was_training) # Revert model back to original training state",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jF7K6W9BwheW",
        "colab_type": "text",
        "_uuid": "6d11a677fe7c58615b400e6aef8173c911989932",
        "_cell_guid": "4cdd5ab4-d82e-4c1f-abc0-4f36bae571ee"
      },
      "cell_type": "markdown",
      "source": "## Model creation\n\nFreeze training for all layers except the last (fc) one"
    },
    {
      "metadata": {
        "id": "SjHLMTldwheY",
        "_uuid": "480b7181f00142865d3e971c799dd42bc9d1f7e5",
        "outputId": "4c40caae-9d25-47e5-fe17-a4f3f944487e",
        "colab_type": "code",
        "colab": {
          "height": 1003,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525007474565,
          "elapsed": 2623,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "_cell_guid": "4be764f7-24ff-4611-8fc6-31b87e3ed171",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "torch.backends.cudnn.benchmark = False\nvgg16 = models.vgg16_bn()\nvgg16.load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\nprint(vgg16.classifier[6].out_features)\n\n\n# Freeze training for all layers\nfor param in vgg16.features.parameters():\n    param.require_grad = False\n    \nnum_features = vgg16.classifier[6].in_features\nfeatures = list(vgg16.classifier.children())[:-1] # Remove last layer\nfeatures.extend([nn.Linear(num_features, len(class_names))]) # Add custom FC layer\nvgg16.classifier = nn.Sequential(*features) # Replace model classifier\nprint(vgg16)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xuaq38UOwhec",
        "_uuid": "bd59ea5c500e55b3ae4bd9cdfeae01bd50818668",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "f45bda67-096e-4de9-a801-98742c34207c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "resume_training = False\n\nif resume_training:\n    print(\"Loading pretrained model..\")\n    vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n    print(\"Loaded!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTJWo25nwhef",
        "_uuid": "45d872d00fcfe93de8938b8741b4526af971c62b",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "df23921b-f26e-496a-9a71-cdf2a9daa34e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "if use_gpu:\n    vgg16.cuda()\n    \ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UcsuUgeDwhei",
        "colab_type": "text",
        "_uuid": "40ffe170725fd3d13be48aba65da375020bad920",
        "_cell_guid": "ffede335-76d7-499a-aff7-32b206133e6c"
      },
      "cell_type": "markdown",
      "source": "## Memory debug utils"
    },
    {
      "metadata": {
        "id": "n3xiQNgRwhei",
        "_uuid": "13a8eaddf9fd1f127d753f04480e6239ce6d1358",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "6b3130ab-438e-42d5-8f11-79130b364c77",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def pretty_size(size):\n    \"\"\"Pretty prints a torch.Size object\"\"\"\n    assert(isinstance(size, torch.Size))\n    return \" × \".join(map(str, size))\n\ndef dump_tensors(gpu_only=True):\n    \"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n    import gc\n    total_size = 0\n    for obj in gc.get_objects():\n        try:\n            if torch.is_tensor(obj):\n                if not gpu_only or obj.is_cuda:\n                    print(\"%s:%s%s %s\" % (type(obj).__name__, \n                                          \" GPU\" if obj.is_cuda else \"\",\n                                          \" pinned\" if obj.is_pinned else \"\",\n                                          pretty_size(obj.size())))\n                    total_size += obj.numel()\n            elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n                if not gpu_only or obj.is_cuda:\n                    print(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n                                                   type(obj.data).__name__, \n                                                   \" GPU\" if obj.is_cuda else \"\",\n                                                   \" pinned\" if obj.data.is_pinned else \"\",\n                                                   \" grad\" if obj.requires_grad else \"\", \n                                                   \" volatile\" if obj.volatile else \"\",\n                                                   pretty_size(obj.data.size())))\n                    total_size += obj.data.numel()\n        except Exception as e:\n            pass        \n    print(\"Total size:\", total_size)\n\n# dump_tensors()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MuVPA5gkwhen",
        "colab_type": "text",
        "_uuid": "5ced4fda7b1a2f175f8795eb5b4d8a1a66c76497",
        "_cell_guid": "996330eb-394c-4916-a924-8d77bc2ffb5b"
      },
      "cell_type": "markdown",
      "source": "## Model visualization (before training)"
    },
    {
      "metadata": {
        "id": "jSa-X3XVwheo",
        "_uuid": "7732406aae91a82348fcb830a5ff5785d22526fb",
        "outputId": "d6f338d4-5379-4fe8-aaec-cc8141b7cbb5",
        "colab_type": "code",
        "colab": {
          "height": 306,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525007488210,
          "elapsed": 1986,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "_cell_guid": "f7aec745-2087-4f60-987d-a34a995fd6a9",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Test before training\")\nvisualize_model(vgg16) #test before training",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDUpsi7cwhes",
        "colab_type": "text",
        "_uuid": "d157eb6d3f1f94af2a369bff6e3e5277482ea6c2",
        "_cell_guid": "46ffdcaf-049a-4dbe-ba6d-b25ccc4ff448"
      },
      "cell_type": "markdown",
      "source": "## Training"
    },
    {
      "metadata": {
        "id": "lHkiBU5fwhet",
        "_uuid": "abe5dc35b31e7971e7d63637866132f89e7d011d",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "8f6936eb-ae6f-44ee-90a9-c7f817ba6eda",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(vgg.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(dataloaders[TRAIN])\n    val_batches = len(dataloaders[VAL])\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_val = 0\n        acc_train = 0\n        acc_val = 0\n        \n        vgg.train(True)\n        \n        for i, data in enumerate(dataloaders[TRAIN]):\n            if i % 100 == 0:\n                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n                \n            # Use half training dataset\n            if i >= train_batches / 2:\n                break\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            \n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.data[0]\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        avg_loss = loss_train / dataset_sizes[TRAIN]\n        avg_acc = acc_train / dataset_sizes[TRAIN]\n        \n        vgg.train(False)\n        vgg.eval()\n            \n        for i, data in enumerate(dataloaders[VAL]):\n            if i % 100 == 0:\n                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n            else:\n                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n            \n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss_val += loss.data[0]\n            acc_val += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        avg_loss_val = loss_val / dataset_sizes[VAL]\n        avg_acc_val = acc_val / dataset_sizes[VAL]\n        \n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n        print('-' * 10)\n        print()\n        \n        if avg_acc_val > best_acc:\n            best_acc = avg_acc_val\n            best_model_wts = copy.deepcopy(vgg.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    vgg.load_state_dict(best_model_wts)\n    return vgg",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1-I_IUUwhew",
        "_uuid": "a0ddf54b1c45b7c61724cbe1e74ca0628f8b1d8e",
        "outputId": "b764e48a-00fd-4eb5-f592-f4386a875ed1",
        "colab_type": "code",
        "colab": {
          "height": 492,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525023518627,
          "elapsed": 304,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "_cell_guid": "53eeb478-e106-49be-9682-0173e76640f8",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7898a0245f8b5c5961945c4a591dfea2ea72ea94",
        "_cell_guid": "f9276b6e-2984-469b-820e-9eb1f7eeced5"
      },
      "cell_type": "markdown",
      "source": "## Model evaluation"
    },
    {
      "metadata": {
        "_uuid": "2e61f744a613d83e499c675908ba8cbfd1f6fdf4",
        "collapsed": true,
        "_cell_guid": "9046ba59-bc84-4823-a6de-bc0685eb3e1c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def eval_model(vgg, criterion):\n    since = time.time()\n    avg_loss = 0\n    avg_acc = 0\n    loss_test = 0\n    acc_test = 0\n    \n    test_batches = len(dataloaders[TEST])\n    print(\"Evaluating model\")\n    print('-' * 10)\n    \n    for i, data in enumerate(dataloaders[TEST]):\n        if i % 100 == 0:\n            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n        vgg.train(False)\n        vgg.eval()\n        inputs, labels = data\n\n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n\n        outputs = vgg(inputs)\n\n        _, preds = torch.max(outputs.data, 1)\n        loss = criterion(outputs, labels)\n\n        loss_test += loss.data[0]\n        acc_test += torch.sum(preds == labels.data)\n\n        del inputs, labels, outputs, preds\n        torch.cuda.empty_cache()\n        \n    avg_loss = loss_test / dataset_sizes[TEST]\n    avg_acc = acc_test / dataset_sizes[TEST]\n    \n    elapsed_time = time.time() - since\n    print()\n    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n    print('-' * 10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2803b24b7002a785833d300413e3bd8891f398f9",
        "collapsed": true,
        "_cell_guid": "f8d905fe-9f7f-484b-b926-9931ca887e34",
        "trusted": false
      },
      "cell_type": "code",
      "source": "eval_model(vgg16, criterion)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19jB0zNQwhez",
        "colab_type": "text",
        "_uuid": "993563466ea328022f5b1bd140cb12f579d92830",
        "_cell_guid": "7e24968f-8834-43dc-8af5-616b2b13acfe"
      },
      "cell_type": "markdown",
      "source": "## Model visualization (after training)"
    },
    {
      "metadata": {
        "id": "hGLvyjZ2whe0",
        "colab": {
          "height": 1122,
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/"
        },
        "_uuid": "4f2ed1c58098075949f93eadc7ba3b5786c7b307",
        "outputId": "497f6621-ee2c-43a5-9b54-917bbbe9b22c",
        "_cell_guid": "c3f7f06c-97fe-4f8e-8b47-f512d4989ecb",
        "collapsed": true,
        "executionInfo": {
          "user_tz": -120,
          "timestamp": 1525025142751,
          "elapsed": 4437,
          "user": {
            "displayName": "Carlo Alberto",
            "userId": "107843268563316278814",
            "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"
          },
          "status": "ok"
        },
        "colab_type": "code",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"Test after training\")\nvisualize_model(vgg16, num_images=32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-BeIb4Uwhe4",
        "_uuid": "59314fce40d45d73295c3022eab6040cfc9aeb82",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "collapsed": true,
        "_cell_guid": "5d0693ed-3add-4522-accc-df80caa4b5e7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "torch.save(vgg16.state_dict(), 'VGG16_v2-OCT_Retina_half_dataset.pt')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VGG16_v2-OCT2017_Retina.ipynb",
      "toc_visible": true,
      "default_view": {},
      "provenance": [],
      "views": {},
      "version": "0.3.2",
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}